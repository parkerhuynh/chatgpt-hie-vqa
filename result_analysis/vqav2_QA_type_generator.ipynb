{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from utils import prep_ans\n",
    "import numpy as np\n",
    "from vqa_question_type_processing import question_type_processing as vqa_question_type_processing\n",
    "from simpsons_question_type_processing import question_type_processing as simpsons_question_type_processing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqav2_anno_paths = [\"/home/ngoc/data/vqav2/new_vqa2_test_annotation.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_ans_to_idx, idx_to_vqa_ans, question_type_map = json.load(open(\"/home/ngoc/githubs/chatgpt-hie-vqa/datasets/answer_dicts_vqav2.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vqa_question_paths = [\"/home/ngoc/data/vqav2/new_vqa2_test_question.json\"]\n",
    "vqa_questions = []\n",
    "for vqa_question_path in vqa_question_paths:\n",
    "    with open(vqa_question_path, 'r') as file:\n",
    "        vqa_questions += json.load(file)\n",
    "        \n",
    "        \n",
    "vqa_processed_questions = {}\n",
    "for question in vqa_questions:\n",
    "    vqa_processed_questions[question[\"question_id\"]] = question[\"question\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqav2_answers = []\n",
    "for vqav2_anno_path in vqav2_anno_paths:\n",
    "    with open(vqav2_anno_path, 'r') as file:\n",
    "        vqav2_answers += json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_ans(ans, ans_to_ix):\n",
    "    ans_prob_dict = {}\n",
    "    for ans_ in ans['answers']:\n",
    "        ans_proc = prep_ans(ans_['answer'])\n",
    "        if ans_proc not in ans_prob_dict:\n",
    "            ans_prob_dict[ans_proc] = 1\n",
    "        else:\n",
    "            ans_prob_dict[ans_proc] += 1\n",
    "    answer_scores = {} \n",
    "    for ans_ in ans_prob_dict:\n",
    "        if ans_ in ans_to_ix:\n",
    "            answer_scores[ans_] = get_score(ans_prob_dict[ans_])\n",
    "    return answer_scores\n",
    "\n",
    "def get_score(occur):\n",
    "    if occur == 0:\n",
    "        return .0 \n",
    "    elif occur == 1:\n",
    "        return round(1/3,2)\n",
    "    elif occur == 2:\n",
    "        return round(2/3,2)\n",
    "    elif occur >= 3:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "for vqav2_answer in  vqav2_answers:\n",
    "    question_id = vqav2_answer[\"question_id\"]\n",
    "    multiple_choice_answer =  prep_ans(vqav2_answer['multiple_choice_answer'])\n",
    "    \n",
    "    if multiple_choice_answer in vqa_ans_to_idx:\n",
    "        question = vqa_processed_questions[question_id]\n",
    "        item = {\"question\": question, \"answer\": multiple_choice_answer}\n",
    "        qa_pairs.append(item)\n",
    "    # process_answers = \", \".join(list(proc_ans(vqav2_answer, vqa_ans_to_idx).keys()))\n",
    "    # question = vqa_processed_questions[question_id]\n",
    "    # if len(process_answers) > 0:\n",
    "    #         item = {\"question\": question, \"answer\": process_answers}\n",
    "    #         qa_pairs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = pd.DataFrame(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = qa_pairs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prompt(question, answer):\n",
    "\n",
    "    prompt = (f'Classify a question-asnwer pair into yes/no, object, color, number, location, human, action, sport, other:\\n'\n",
    "                f'Question: What is the capital of France?.\\n'\n",
    "                f'Answer: Paris.\\n'\n",
    "                f'Type: location\\n\\n'\n",
    "                f'Question: {question}.\\n'\n",
    "                f'Answer: {answer}.\\n'\n",
    "                f'Type:')\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs[\"prompt\"] = qa_pairs[[\"question\", \"answer\"]].apply(lambda x: map_prompt(x[\"question\"], x[\"answer\"]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs.to_csv(\"full_vqav2_qa_prompting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify a question-asnwer pair into yes/no, object, color, number, location, human, action, sport, other:\n",
      "Question: What is the capital of France?.\n",
      "Answer: Paris.\n",
      "Type: location\n",
      "\n",
      "Question: Who are riding motorcycles?.\n",
      "Answer: police.\n",
      "Type:\n"
     ]
    }
   ],
   "source": [
    "print(qa_pairs.iloc[1000].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs[:45000].to_csv(\"first_vqav2_qa_prompting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs[45000:].to_csv(\"second_vqav2_qa_prompting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is this photo taken looking through?</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What position is this man playing?</td>\n",
       "      <td>pitcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What color is the players shirt?</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this man a professional baseball player?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What color is the snow?</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94491</th>\n",
       "      <td>Is it a light or heavy rain?</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94494</th>\n",
       "      <td>Can he be sharpening blades?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94495</th>\n",
       "      <td>Is this a normal thing to see in recent history?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94496</th>\n",
       "      <td>What links the two chains together?</td>\n",
       "      <td>ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94498</th>\n",
       "      <td>Is this made of metal?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73859 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question   answer\n",
       "0             What is this photo taken looking through?      net\n",
       "1                    What position is this man playing?  pitcher\n",
       "2                      What color is the players shirt?   orange\n",
       "3           Is this man a professional baseball player?      yes\n",
       "4                               What color is the snow?    white\n",
       "...                                                 ...      ...\n",
       "94491                      Is it a light or heavy rain?    light\n",
       "94494                      Can he be sharpening blades?      yes\n",
       "94495  Is this a normal thing to see in recent history?       no\n",
       "94496               What links the two chains together?     ring\n",
       "94498                            Is this made of metal?      yes\n",
       "\n",
       "[73859 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique question-answer pairs: 107190\n",
      "Number of duplicate question-answer pairs: 8106\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "qa_pair_counts = {}\n",
    "file_paths = ['vqav2_qa_type_1.json', 'vqav2_qa_type_2.json', \n",
    "              'vqav2_qa_type_3.json', \"new_1.json\", \"new_2.json\",\n",
    "              \"new_3.json\"]\n",
    "vqa_test_qa_type = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            question = data['question']\n",
    "            answer = data['answer']\n",
    "            \n",
    "            qa_pair = (question, answer)\n",
    "            if qa_pair in qa_pair_counts:\n",
    "                qa_pair_counts[qa_pair] += 1\n",
    "            else:\n",
    "                question_answer_type = data[\"question_answer_type\"] if 'question_answer_type' in data else data[\"question_type\"]\n",
    "                item = {\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"question_answer_type\": question_answer_type\n",
    "                }\n",
    "                qa_pair_counts[qa_pair] = 1\n",
    "                vqa_test_qa_type.append(item)\n",
    "                \n",
    "                \n",
    "\n",
    "num_unique_pairs = len(qa_pair_counts)\n",
    "num_duplicates = sum(count > 1 for count in qa_pair_counts.values())\n",
    "\n",
    "print(\"Number of unique question-answer pairs:\", num_unique_pairs)\n",
    "print(\"Number of duplicate question-answer pairs:\", num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_test_qa_type = pd.DataFrame(vqa_test_qa_type)\n",
    "vqa_test_qa_type = vqa_test_qa_type.rename(columns={\"question_type\": \"qa_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_test_qa_type.to_csv(\"vqa_test_qa_type.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
