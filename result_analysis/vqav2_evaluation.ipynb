{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from utils import prep_ans\n",
    "import numpy as np\n",
    "from vqa_question_type_processing import question_type_processing as vqa_question_type_processing\n",
    "from simpsons_question_type_processing import question_type_processing as simpsons_question_type_processing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqav2_anno_paths = [\"/home/ngoc/data/vqav2/new_vqa2_test_annotation.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_ans_to_idx, idx_to_vqa_ans, question_type_map = json.load(open(\"/home/ngoc/githubs/chatgpt-hie-vqa/datasets/answer_dicts_vqav2.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prompt(question, answer):\n",
    "\n",
    "    prompt = (f'Classify a question-asnwer pair into yes/no, object, color, number, location, human, action, sport, other:\\n'\n",
    "                f'Question: What is the capital of France?.\\n'\n",
    "                f'Answer: Paris.\\n'\n",
    "                f'Type: location\\n\\n'\n",
    "                f'Question: {question}.\\n'\n",
    "                f'Answer: {answer}.\\n'\n",
    "                f'Type:')\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_question_type_dict = {}\n",
    "with open(\"/home/ngoc/githubs/Question-Analysis/datasets/train_question_type_gpt_v6_vqav2.json\", 'r') as file:\n",
    "    for line in file:\n",
    "        question_object = json.loads(line)\n",
    "        question_str = question_object[\"question\"]\n",
    "        question_type = question_object[\"question_type\"]\n",
    "        question_type = vqa_question_type_processing(question_type)\n",
    "        vqa_question_type_dict[question_str] = question_type\n",
    "file.close()\n",
    "\n",
    "\n",
    "vqa_question_paths = [ \"/home/ngoc/data/vqav2/new_vqa2_test_question.json\"]\n",
    "vqa_questions = []\n",
    "for vqa_question_path in vqa_question_paths:\n",
    "    with open(vqa_question_path, 'r') as file:\n",
    "        vqa_questions += json.load(file)\n",
    "        \n",
    "        \n",
    "vqa_processed_questions = {}\n",
    "for question in vqa_questions:\n",
    "    # print(question)\n",
    "    # print(vqa_question_type_dict[question[\"question\"])\n",
    "    # a\n",
    "    vqa_processed_questions[question[\"question_id\"]] = {\n",
    "        \"question_type\": vqa_question_type_dict[question[\"question\"]],\n",
    "        \"question\": question[\"question\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vqav2_answers = []\n",
    "for vqav2_anno_path in vqav2_anno_paths:\n",
    "    with open(vqav2_anno_path, 'r') as file:\n",
    "        vqav2_answers += json.load(file)\n",
    "\n",
    "def proc_ans(ans, ans_to_ix):\n",
    "    ans_prob_dict = {}\n",
    "    for ans_ in ans['answers']:\n",
    "        ans_proc = prep_ans(ans_['answer'])\n",
    "        if ans_proc not in ans_prob_dict:\n",
    "            ans_prob_dict[ans_proc] = 1\n",
    "        else:\n",
    "            ans_prob_dict[ans_proc] += 1\n",
    "    answer_scores = {} \n",
    "    for ans_ in ans_prob_dict:\n",
    "        if ans_ in ans_to_ix:\n",
    "            answer_scores[ans_] = get_score(ans_prob_dict[ans_])\n",
    "    return answer_scores\n",
    "\n",
    "def get_score(occur):\n",
    "    if occur == 0:\n",
    "        return .0 \n",
    "    elif occur == 1:\n",
    "        return round(1/3,2)\n",
    "    elif occur == 2:\n",
    "        return round(2/3,2)\n",
    "    elif occur >= 3:\n",
    "        return 1\n",
    "\n",
    "vqav2_processed_answers = {}\n",
    "for vqav2_answer in  vqav2_answers:\n",
    "    question_id = vqav2_answer[\"question_id\"]\n",
    "    vqav2_processed_answers[question_id] = {}\n",
    "    multiple_choice_answer =  prep_ans(vqav2_answer['multiple_choice_answer'])\n",
    "    process_answers = proc_ans(vqav2_answer, vqa_ans_to_idx)\n",
    "    vqav2_processed_answers[question_id][\"answer_dict\"] = process_answers\n",
    "    vqav2_processed_answers[question_id][\"multiple_choice_answer\"] = multiple_choice_answer\n",
    "    vqav2_processed_answers[question_id][\"question_type\"] = vqa_processed_questions[question_id][\"question_type\"]\n",
    "    vqav2_processed_answers[question_id][\"question\"] = vqa_processed_questions[question_id][\"question\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pd.read_csv(\"test_predictions.csv\")\n",
    "test_result[\"multiple_choice_answer\"] = test_result[\"question_id\"].apply(lambda x: vqav2_processed_answers[x][\"multiple_choice_answer\"])\n",
    "test_result = test_result[test_result[\"multiple_choice_answer\"].isin(vqa_ans_to_idx.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>multiple_choice_answer</th>\n",
       "      <th>qa_type</th>\n",
       "      <th>vqa_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is this photo taken looking through?</td>\n",
       "      <td>net</td>\n",
       "      <td>object</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What position is this man playing?</td>\n",
       "      <td>pitcher</td>\n",
       "      <td>sport</td>\n",
       "      <td>pitcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What color is the players shirt?</td>\n",
       "      <td>orange</td>\n",
       "      <td>color</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this man a professional baseball player?</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What color is the snow?</td>\n",
       "      <td>white</td>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question multiple_choice_answer qa_type  \\\n",
       "0    What is this photo taken looking through?                    net  object   \n",
       "1           What position is this man playing?                pitcher   sport   \n",
       "2             What color is the players shirt?                 orange   color   \n",
       "3  Is this man a professional baseball player?                    yes  yes/no   \n",
       "4                      What color is the snow?                  white   color   \n",
       "\n",
       "  vqa_prediction  \n",
       "0            net  \n",
       "1        pitcher  \n",
       "2         orange  \n",
       "3            yes  \n",
       "4          white  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer_pair_type = pd.read_csv(\"vqa_test_qa_type.csv\")\n",
    "question_answer_pair_type = question_answer_pair_type.rename(columns={\"answer\": \"multiple_choice_answer\"})\n",
    "question_answer_pair_type[\"vqa_prediction\"] = question_answer_pair_type[\"multiple_choice_answer\"]\n",
    "question_answer_pair_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_answer_scores(question_id, vqa_prediction):\n",
    "    score_dict = vqav2_processed_answers[question_id][\"answer_dict\"]\n",
    "    if vqa_prediction in score_dict.keys():\n",
    "        return score_dict[vqa_prediction]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_result[\"vqa_prediction\"] = test_result[\"prediction\"]\n",
    "except:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[\"vqa_score\"] = test_result[[\"question_id\", \"vqa_prediction\"]].apply(lambda x: map_answer_scores(x[\"question_id\"], x[\"vqa_prediction\"]), axis = 1)\n",
    "test_result[\"question_type\"] = test_result[\"question_id\"].apply(lambda x: vqav2_processed_answers[x][\"question_type\"])\n",
    "test_result[\"question\"] = test_result[\"question_id\"].apply(lambda x: vqav2_processed_answers[x][\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of test set: 94499\n"
     ]
    }
   ],
   "source": [
    "print(f\"len of test set: {len(test_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of test set: 94483\n"
     ]
    }
   ],
   "source": [
    "test_result= pd.merge(test_result, question_answer_pair_type[['question', 'multiple_choice_answer', 'qa_type']], on=['question', 'multiple_choice_answer'], how='inner')\n",
    "test_result = test_result.rename(columns ={'qa_type': 'qa_type_label'})\n",
    "print(f\"len of test set: {len(test_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pd.merge(test_result, question_answer_pair_type[['question', 'vqa_prediction', 'qa_type']], on=['question', 'vqa_prediction'], how='left')\n",
    "test_result = test_result.rename(columns ={'qa_type': 'qa_type_prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_645361/3088051369.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_result_non_qa_type[\"answer\"] = test_result_non_qa_type[\"vqa_prediction\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of new qa pairs 33317\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Existing QA pairs don't have a type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumber of new qa pairs \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(test_result_non_qa_type)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m test_result_non_qa_type\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mnew_qa_pairs_for_evaluation.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFalse\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExisting QA pairs don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a type\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Existing QA pairs don't have a type"
     ]
    }
   ],
   "source": [
    "if test_result[\"qa_type_prediction\"].isna().any():\n",
    "    \n",
    "    test_result_non_qa_type = test_result[test_result[\"qa_type_prediction\"].isna()]\n",
    "    test_result_non_qa_type[\"answer\"] = test_result_non_qa_type[\"vqa_prediction\"]\n",
    "    test_result_non_qa_type = test_result_non_qa_type[[\"answer\", \"question\"]]\n",
    "    test_result_non_qa_type = test_result_non_qa_type.drop_duplicates()\n",
    "    test_result_non_qa_type = test_result_non_qa_type.reset_index(drop=True)\n",
    "    test_result_non_qa_type[\"prompt\"] = test_result_non_qa_type[[\"question\", \"answer\"]].apply(lambda x: map_prompt(x[\"question\"], x[\"answer\"]), axis =1)\n",
    "    print(f\"number of new qa pairs {len(test_result_non_qa_type)}\")\n",
    "    test_result_non_qa_type.to_csv(\"new_qa_pairs_for_evaluation.csv\", index=\"False\")\n",
    "    raise Exception(\"Existing QA pairs don't have a type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>multiple_choice_answer</th>\n",
       "      <th>vqa_prediction</th>\n",
       "      <th>vqa_score</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>qa_type_label</th>\n",
       "      <th>qa_type_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300383000</td>\n",
       "      <td>black</td>\n",
       "      <td>white</td>\n",
       "      <td>black</td>\n",
       "      <td>0.00</td>\n",
       "      <td>color</td>\n",
       "      <td>What color are the tennis shoes?</td>\n",
       "      <td>color</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290189005</td>\n",
       "      <td>north</td>\n",
       "      <td>left</td>\n",
       "      <td>north</td>\n",
       "      <td>0.00</td>\n",
       "      <td>location</td>\n",
       "      <td>Which direction is the train going?</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119604001</td>\n",
       "      <td>yellow</td>\n",
       "      <td>orange</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1.00</td>\n",
       "      <td>color</td>\n",
       "      <td>What is the main color of the truck?</td>\n",
       "      <td>color</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4647001</td>\n",
       "      <td>black</td>\n",
       "      <td>white</td>\n",
       "      <td>black</td>\n",
       "      <td>0.00</td>\n",
       "      <td>color</td>\n",
       "      <td>What color is the duck's beak?</td>\n",
       "      <td>color</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>545285003</td>\n",
       "      <td>solid</td>\n",
       "      <td>0</td>\n",
       "      <td>solid</td>\n",
       "      <td>0.67</td>\n",
       "      <td>object</td>\n",
       "      <td>What pattern is on the seat cushions?</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94469</th>\n",
       "      <td>406462005</td>\n",
       "      <td>beach</td>\n",
       "      <td>desert</td>\n",
       "      <td>beach</td>\n",
       "      <td>0.67</td>\n",
       "      <td>location</td>\n",
       "      <td>Where does the horse race take place?</td>\n",
       "      <td>location</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>421763000</td>\n",
       "      <td>apples</td>\n",
       "      <td>oranges</td>\n",
       "      <td>apples</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>Which fruits are these?</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94477</th>\n",
       "      <td>36953015</td>\n",
       "      <td>living room</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>living room</td>\n",
       "      <td>0.00</td>\n",
       "      <td>yes/no</td>\n",
       "      <td>Is the room on the left a kitchen or a breakroom?</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94478</th>\n",
       "      <td>508311002</td>\n",
       "      <td>eating</td>\n",
       "      <td>standing</td>\n",
       "      <td>eating</td>\n",
       "      <td>0.33</td>\n",
       "      <td>action</td>\n",
       "      <td>What are these birds doing?</td>\n",
       "      <td>action</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94482</th>\n",
       "      <td>37868000</td>\n",
       "      <td>stove</td>\n",
       "      <td>box</td>\n",
       "      <td>stove</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>What is the appliance sitting on?</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35519 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id   prediction multiple_choice_answer vqa_prediction  \\\n",
       "0        300383000        black                  white          black   \n",
       "2        290189005        north                   left          north   \n",
       "4        119604001       yellow                 orange         yellow   \n",
       "6          4647001        black                  white          black   \n",
       "15       545285003        solid                      0          solid   \n",
       "...            ...          ...                    ...            ...   \n",
       "94469    406462005        beach                 desert          beach   \n",
       "94475    421763000       apples                oranges         apples   \n",
       "94477     36953015  living room                kitchen    living room   \n",
       "94478    508311002       eating               standing         eating   \n",
       "94482     37868000        stove                    box          stove   \n",
       "\n",
       "       vqa_score question_type  \\\n",
       "0           0.00         color   \n",
       "2           0.00      location   \n",
       "4           1.00         color   \n",
       "6           0.00         color   \n",
       "15          0.67        object   \n",
       "...          ...           ...   \n",
       "94469       0.67      location   \n",
       "94475       0.00        object   \n",
       "94477       0.00        yes/no   \n",
       "94478       0.33        action   \n",
       "94482       0.00        object   \n",
       "\n",
       "                                                question qa_type_label  \\\n",
       "0                       What color are the tennis shoes?         color   \n",
       "2                    Which direction is the train going?         other   \n",
       "4                   What is the main color of the truck?         color   \n",
       "6                         What color is the duck's beak?         color   \n",
       "15                 What pattern is on the seat cushions?        object   \n",
       "...                                                  ...           ...   \n",
       "94469              Where does the horse race take place?      location   \n",
       "94475                            Which fruits are these?        object   \n",
       "94477  Is the room on the left a kitchen or a breakroom?        object   \n",
       "94478                        What are these birds doing?        action   \n",
       "94482                  What is the appliance sitting on?        object   \n",
       "\n",
       "      qa_type_prediction  \n",
       "0                    NaN  \n",
       "2                    NaN  \n",
       "4                    NaN  \n",
       "6                    NaN  \n",
       "15                   NaN  \n",
       "...                  ...  \n",
       "94469                NaN  \n",
       "94475                NaN  \n",
       "94477                NaN  \n",
       "94478                NaN  \n",
       "94482                NaN  \n",
       "\n",
       "[35519 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_overall_accuracy  = test_result[\"vqa_score\"].sum()/len(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_unique_labels = [\"yes/no\", \"object\", \"color\", \"number\", \"location\",\"human\", \"action\", \"sport\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5500317517436999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_accurancy = {}\n",
    "for question_type_value in sorted_unique_labels:\n",
    "    sub_test_result = test_result[test_result[\"question_label\"] == question_type_value]\n",
    "    sub_accuracy_i = sub_test_result[\"vqa_score\"].sum()/len(sub_test_result)\n",
    "    sub_accurancy[\"test_vqa_accuracy_\" + question_type_value] = sub_accuracy_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_vqa_accuracy_yes/no': 0.6705244693021483,\n",
       " 'test_vqa_accuracy_object': 0.45501823178142997,\n",
       " 'test_vqa_accuracy_color': 0.45560325810283386,\n",
       " 'test_vqa_accuracy_number': 0.37053732602277517,\n",
       " 'test_vqa_accuracy_location': 0.5301192472517235,\n",
       " 'test_vqa_accuracy_human': 0.4644654498044329,\n",
       " 'test_vqa_accuracy_action': 0.5544229607250755,\n",
       " 'test_vqa_accuracy_sport': 0.7490697674418604,\n",
       " 'test_vqa_accuracy_other': 0.46175619047619043}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"bi6l2w1x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngocdunghuynh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ngoc/githubs/chatgpt-hie-vqa/result_analysis/wandb/run-20240325_152136-bi6l2w1x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/ngocdunghuynh/VQA%20new/runs/bi6l2w1x' target=\"_blank\">rank-0</a></strong> to <a href='https://wandb.ai/ngocdunghuynh/VQA%20new' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ngocdunghuynh/VQA%20new' target=\"_blank\">https://wandb.ai/ngocdunghuynh/VQA%20new</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ngocdunghuynh/VQA%20new/runs/bi6l2w1x' target=\"_blank\">https://wandb.ai/ngocdunghuynh/VQA%20new/runs/bi6l2w1x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ngocdunghuynh/VQA%20new/runs/bi6l2w1x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4081ba09a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.init(project=\"VQA new\", id=run_id, resume=\"must\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"test_vqa_accuracy\": test_overall_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log(sub_accurancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question_type_accuracy = classification_report(test_result[\"question_prediction\"], test_result[\"question_label\"], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_question_type_accuracy = {}\n",
    "for key in test_question_type_accuracy:\n",
    "    new_test_question_type_accuracy[\"question_type_\" + key] = test_question_type_accuracy[key]\n",
    "del(test_question_type_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log(new_test_question_type_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_result['question_label']\n",
    "y_pred = test_result['question_prediction']\n",
    "sorted_unique_labels = [\"yes/no\", \"object\", \"color\", \"number\", \"location\",\"human\", \"action\", \"sport\", \"other\"]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=sorted_unique_labels)\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(20, 9))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', \n",
    "            xticklabels=sorted_unique_labels, yticklabels=sorted_unique_labels, \n",
    "            cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Type')\n",
    "plt.ylabel('True Type')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', \n",
    "            xticklabels=sorted_unique_labels, yticklabels=sorted_unique_labels, \n",
    "            cmap='Blues', cbar=False)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.xlabel('Predicted Type')\n",
    "plt.ylabel('True Type')\n",
    "plt.suptitle(f'Test Confusion Matrix')\n",
    "buffer = BytesIO()\n",
    "plt.savefig(buffer, format='png')\n",
    "buffer.seek(0)\n",
    "image = Image.open(buffer)\n",
    "image_array = np.array(image)\n",
    "wandb.log({\"Test Confusion Matrix\": wandb.Image(image_array)})\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Ensure read and write access to run files dir: /home/ngoc/githubs/chatgpt-hie-vqa/result_analysis/wandb/run-20240325_152136-bi6l2w1x/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eb0154d23442fe853ee1606a4d25ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.124 MB uploaded\\r'), FloatProgress(value=0.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>question_type_accuracy</td><td>▁</td></tr><tr><td>test_vqa_accuracy</td><td>▁</td></tr><tr><td>test_vqa_accuracy_action</td><td>▁</td></tr><tr><td>test_vqa_accuracy_color</td><td>▁</td></tr><tr><td>test_vqa_accuracy_human</td><td>▁</td></tr><tr><td>test_vqa_accuracy_location</td><td>▁</td></tr><tr><td>test_vqa_accuracy_number</td><td>▁</td></tr><tr><td>test_vqa_accuracy_object</td><td>▁</td></tr><tr><td>test_vqa_accuracy_other</td><td>▁</td></tr><tr><td>test_vqa_accuracy_sport</td><td>▁</td></tr><tr><td>test_vqa_accuracy_yes/no</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_accuracy</td><td>0.56812</td></tr><tr><td>best_epoch</td><td>53</td></tr><tr><td>epoch</td><td>64</td></tr><tr><td>question_type_accuracy</td><td>0.96479</td></tr><tr><td>question_type_loss</td><td>1.33117</td></tr><tr><td>test_accuracy</td><td>0.54496</td></tr><tr><td>test_vqa_accuracy</td><td>0.54496</td></tr><tr><td>test_vqa_accuracy_action</td><td>0.55442</td></tr><tr><td>test_vqa_accuracy_color</td><td>0.4556</td></tr><tr><td>test_vqa_accuracy_human</td><td>0.46447</td></tr><tr><td>test_vqa_accuracy_location</td><td>0.53012</td></tr><tr><td>test_vqa_accuracy_number</td><td>0.37054</td></tr><tr><td>test_vqa_accuracy_object</td><td>0.45502</td></tr><tr><td>test_vqa_accuracy_other</td><td>0.46176</td></tr><tr><td>test_vqa_accuracy_sport</td><td>0.74907</td></tr><tr><td>test_vqa_accuracy_yes/no</td><td>0.67052</td></tr><tr><td>total_loss</td><td>15.4285</td></tr><tr><td>train_loss</td><td>136.05141</td></tr><tr><td>train_question_type_accuracy</td><td>0.97348</td></tr><tr><td>train_question_type_loss</td><td>6.0628</td></tr><tr><td>train_vqa_accuracy</td><td>0.69971</td></tr><tr><td>train_vqa_loss</td><td>129.98859</td></tr><tr><td>val_loss</td><td>382.23633</td></tr><tr><td>val_question_type_accuracy</td><td>0.95397</td></tr><tr><td>val_question_type_loss</td><td>22.06928</td></tr><tr><td>val_vqa_accuracy</td><td>0.56745</td></tr><tr><td>val_vqa_loss</td><td>360.16721</td></tr><tr><td>vqa_loss</td><td>14.09734</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rank-0</strong> at: <a href='https://wandb.ai/ngocdunghuynh/VQA%20new/runs/bi6l2w1x' target=\"_blank\">https://wandb.ai/ngocdunghuynh/VQA%20new/runs/bi6l2w1x</a><br/>Synced 3 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240325_152136-bi6l2w1x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
